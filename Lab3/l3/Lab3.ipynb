{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyun-Joon Yang\n",
    "### yanghyun@usc.edu\n",
    "### CSCI 360\n",
    "### Lab 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from lab3_utils import edit_distance, feature_names\n",
    "\n",
    "# Hint: Consider how to utilize np.unique()\n",
    "def preprocess_data(training_inputs, testing_inputs, training_labels, testing_labels):\n",
    "    processed_training_inputs, processed_testing_inputs = ([], [])\n",
    "    processed_training_labels, processed_testing_labels = ([], [])\n",
    "    # VVVVV YOUR CODE GOES ERE VVVVV $\n",
    "\n",
    "    # raw & processed inputs\n",
    "    inputs = [training_inputs, testing_inputs]\n",
    "    labels = [training_labels, testing_labels]\n",
    "    processed = [[], []]\n",
    "    # indices of ordinal vs discrete feature\n",
    "    ordinals = {0, 2, 3, 5}\n",
    "    discretes = {1, 4, 6, 7, 8}\n",
    "\n",
    "    # pre-processing\n",
    "    for i in range(len(inputs)):\n",
    "        # basic constants\n",
    "        m = inputs[i].shape[0]\n",
    "        n = inputs[i].shape[1]\n",
    "\n",
    "        # replace ?, deal with categorical\n",
    "        for j in range(n):\n",
    "            # convert to right data type\n",
    "            feature = np.array(inputs[i][:,j], dtype=str)\n",
    "            # find mode\n",
    "            vals, occurs = np.unique(feature, return_counts=True)\n",
    "            mode = vals[np.argmax(occurs)]\n",
    "            # print(vals, occurs, mode)\n",
    "            # replace ?\n",
    "            if '?' in vals:\n",
    "                feature = np.char.replace(feature, '?', mode)\n",
    "\n",
    "            # deal with categorical\n",
    "            if j in ordinals:\n",
    "                mapper = {}\n",
    "                # age\n",
    "                if j == 0:\n",
    "                    for k in range(9):\n",
    "                        key = str(k+1)+'0-'+str(k+1)+'9'\n",
    "                        mapper[key] = str(k+1)\n",
    "                        feature = np.char.replace(feature, key, mapper[key])\n",
    "                # tumor size\n",
    "                elif j == 2:\n",
    "                    for k in range(12):\n",
    "                        lower = k*5\n",
    "                        upper = (k+1)*5-1\n",
    "                        key = str(lower)+'-'+str(upper)\n",
    "                        mapper[key] = str(k+1)\n",
    "                        feature = np.char.replace(feature, key, mapper[key])\n",
    "                # inv-nodes\n",
    "                elif j == 3:\n",
    "                    for k in range(13):\n",
    "                        lower = (k*3)\n",
    "                        upper = lower + 2\n",
    "                        if k == 12:\n",
    "                            upper = lower + 3\n",
    "                        key = str(lower)+'-'+str(upper)\n",
    "                        mapper[key] = str(k+1)\n",
    "                        feature = np.char.replace(feature, key, mapper[key])\n",
    "                # deg-malig\n",
    "                else:\n",
    "                    for k in range(3):\n",
    "                        key = str(k+1)\n",
    "                        mapper[key] = str(k+1)\n",
    "                        feature = np.char.replace(feature, key, mapper[key])\n",
    "            elif j in discretes:\n",
    "                # multiple levels\n",
    "                if j in {1, 7}:\n",
    "                    # menopause\n",
    "                    if j == 1:\n",
    "                        keys = ['lt40', 'ge40', 'premeno']\n",
    "                    # breast-quad\n",
    "                    else:\n",
    "                        keys = ['left_up', 'left_low', 'right_up', 'right_low', 'central']\n",
    "                    new_feature = np.zeros((m, len(keys)))\n",
    "                    # create dict\n",
    "                    indices = {}\n",
    "                    for k in range(len(keys)):\n",
    "                        indices[keys[k]] = k\n",
    "                        # fill in auxilliary\n",
    "                    for k in range(m):\n",
    "                        new_feature[k, indices[feature[k]]] = 1\n",
    "                    feature = new_feature\n",
    "                # 2 levels\n",
    "                else:\n",
    "                    # breast\n",
    "                    if j == 6:\n",
    "                        keys = ['left', 'right']\n",
    "                    # node-caps, irradiat\n",
    "                    else:\n",
    "                        keys = ['yes', 'no']\n",
    "                    feature[feature == keys[0]] = 1\n",
    "                    feature[feature == keys[1]] = 0\n",
    "\n",
    "            # make processed matrix\n",
    "            feature = np.array(feature, dtype=int)\n",
    "            if feature.ndim < 2:\n",
    "                feature = np.expand_dims(feature, axis=1)\n",
    "            if type(processed[i]) == list:\n",
    "                processed[i] = feature\n",
    "            else:\n",
    "                processed[i] = np.concatenate((processed[i], feature), axis=1)\n",
    "\n",
    "        # turn labels into 0 or 1\n",
    "        labels[i] = np.array(labels[i], dtype=str)\n",
    "        labels[i] = np.char.replace(labels[i], 'no-recurrence-events', '0')\n",
    "        labels[i] = np.char.replace(labels[i], 'recurrence-events', '1')\n",
    "        labels[i] = np.array(labels[i], dtype=int)\n",
    "\n",
    "    processed_training_inputs = processed[0]\n",
    "    processed_testing_inputs = processed[1]\n",
    "    processed_training_labels = labels[0]\n",
    "    processed_testing_labels = labels[1]\n",
    "\n",
    "    # print(processed_training_inputs)\n",
    "    # print(processed_training_labels)\n",
    "    # print(training_inputs[0,:], processed_training_inputs[0,:])\n",
    "    # print(len(training_labels) == len(processed_training_labels))\n",
    "    # print(processed_testing_inputs)\n",
    "    # print(processed_testing_labels)\n",
    "    # print(testing_inputs[0, :], processed_testing_inputs[0, :])\n",
    "    # print(len(testing_labels) == len(processed_testing_labels))\n",
    "\n",
    "    # ^^^^^ YOUR CODE GOES ERE ^^^^^ $\n",
    "    return processed_training_inputs, processed_testing_inputs, processed_training_labels, processed_testing_labels\n",
    "\n",
    "\n",
    "\n",
    "# Hint: consider how to utilize np.argsort()\n",
    "def k_nearest_neighbors(predict_on, reference_points, reference_labels, k, l, weighted):\n",
    "    assert len(predict_on) > 0, f\"parameter predict_on needs to be of length 0 or greater\"\n",
    "    assert len(reference_points) > 0, f\"parameter reference_points needs to be of length 0 or greater\"\n",
    "    assert len(reference_labels) > 0, f\"parameter reference_labels needs to be of length 0 or greater\"\n",
    "    assert len(reference_labels) == len(reference_points), f\"reference_points and reference_labels need to be the\" \\\n",
    "                                                           f\" same length\"\n",
    "    predictions = []\n",
    "    # VVVVV YOUR CODE GOES ERE VVVVV $\n",
    "\n",
    "    # get distances for every x, x*\n",
    "    m_2 = predict_on.shape[0]\n",
    "    m_1 = reference_points.shape[0]\n",
    "    distances = np.zeros((m_1, m_2))\n",
    "    for i in range(m_1):\n",
    "        for j in range(m_2):\n",
    "            distances[i, j] = edit_distance(reference_points[i, :], predict_on[j, :], l)\n",
    "    # nonmatching or matching elements for when l = -1??\n",
    "\n",
    "    # get k neighbors for each x*\n",
    "    orders = np.argsort(distances, axis=0)\n",
    "    neighbors = orders[0:k, 0:m_2]\n",
    "\n",
    "    # find mode & add to predictions for each x*\n",
    "    if weighted:\n",
    "        scores = np.zeros(m_2)\n",
    "        epsilon = 0.0001\n",
    "        # calculate score\n",
    "        for i in range(m_2):\n",
    "            num = 0\n",
    "            denom = 0\n",
    "            for j in range(k):\n",
    "                order = orders[j,i]\n",
    "                y = reference_labels[order]\n",
    "                dist = edit_distance(reference_points[order,:], predict_on[i,:], l)\n",
    "                num += (y / dist)\n",
    "                denom += (1/(dist + epsilon))\n",
    "                # print(y, dist, num, denom)\n",
    "            scores[i] = num / denom\n",
    "        # classify\n",
    "        scores[scores >= 0.5] = 1\n",
    "        scores[scores < 0.5] = 0\n",
    "        predictions = list(scores)\n",
    "    else:\n",
    "        for i in range(m_2):\n",
    "            vals, occurs = np.unique(neighbors[:,i], return_counts=True)\n",
    "            maxoccur = occurs[0]\n",
    "            ind = 0\n",
    "            for i in range(len(occurs)):\n",
    "                if occurs[i] > maxoccur:\n",
    "                    maxoccur = occurs[i]\n",
    "                    ind = i\n",
    "                # break tie in favor of recurrence\n",
    "                elif occurs[i] == maxoccur:\n",
    "                    if reference_labels[i] == 1:\n",
    "                        ind = i\n",
    "            mode = vals[ind]\n",
    "            # mode = vals[np.argmax(occurs)]\n",
    "            predictions.append(reference_labels[mode])\n",
    "\n",
    "    # ^^^^^ YOUR CODE GOES ERE ^^^^^ $\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hyun-\\OneDrive\\바탕 화면\\Classes\\FALL 2020\\CSCI 360\\Labs\\Lab3\\l3\\lab3.py:167: RuntimeWarning: invalid value encountered in true_divide\n",
      "  num += (y / dist)\n",
      "C:\\Users\\Hyun-\\OneDrive\\바탕 화면\\Classes\\FALL 2020\\CSCI 360\\Labs\\Lab3\\l3\\lab3.py:172: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  scores[scores >= 0.5] = 1\n",
      "C:\\Users\\Hyun-\\OneDrive\\바탕 화면\\Classes\\FALL 2020\\CSCI 360\\Labs\\Lab3\\l3\\lab3.py:173: RuntimeWarning: invalid value encountered in less\n",
      "  scores[scores < 0.5] = 0\n",
      "C:\\Users\\Hyun-\\OneDrive\\바탕 화면\\Classes\\FALL 2020\\CSCI 360\\Labs\\Lab3\\l3\\lab3_utils.py:26: RuntimeWarning: invalid value encountered in power\n",
      "  return np.power(\n",
      "C:\\Users\\Hyun-\\OneDrive\\바탕 화면\\Classes\\FALL 2020\\CSCI 360\\Labs\\Lab3\\l3\\lab3.py:167: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  num += (y / dist)\n"
     ]
    }
   ],
   "source": [
    "from lab3_utils import (\n",
    "    accuracy_score,\n",
    "    load_data\n",
    ")\n",
    "from lab3 import k_nearest_neighbors, preprocess_data\n",
    "\n",
    "k_max = 30\n",
    "l_norms = [-1, 1, 2, 3, 4, 5, 6, np.inf]\n",
    "weighting_options = [True, False]\n",
    "inaccuracies = np.zeros((k_max, len(l_norms), len(weighting_options)))\n",
    "\n",
    "raw_data = load_data()\n",
    "processed_training_inputs, processed_testing_inputs, processed_training_labels, processed_testing_labels =\\\n",
    "    preprocess_data(*raw_data)\n",
    "\n",
    "for k in range(1, k_max+1):\n",
    "    for l_i, l_norm in enumerate(l_norms):\n",
    "        for w, weighting in enumerate(weighting_options):\n",
    "            predicted_labels = k_nearest_neighbors(\n",
    "                predict_on=processed_testing_inputs,\n",
    "                reference_points=processed_training_inputs,\n",
    "                reference_labels=processed_training_labels,\n",
    "                k=k,\n",
    "                l=l_norm,\n",
    "                weighted=weighting\n",
    "            )\n",
    "            inaccuracies[k-1, l_i, w] = 1-accuracy_score(processed_testing_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY\n",
      "--------------------\n",
      "Row -> k (1 to 30)\n",
      "Col -> l (-1, 1, 2, 3, 4, 5, 6, inf)\n",
      "----------\n",
      "Weighted\n",
      "[[0.61111111 0.43055556 0.47222222 0.44444444 0.47222222 0.47222222\n",
      "  0.47222222 0.47222222]\n",
      " [0.65277778 0.5        0.5        0.5        0.51388889 0.51388889\n",
      "  0.51388889 0.48611111]\n",
      " [0.65277778 0.44444444 0.38888889 0.36111111 0.375      0.375\n",
      "  0.375      0.43055556]\n",
      " [0.65277778 0.44444444 0.38888889 0.40277778 0.40277778 0.40277778\n",
      "  0.38888889 0.43055556]\n",
      " [0.72222222 0.36111111 0.375      0.36111111 0.34722222 0.34722222\n",
      "  0.34722222 0.41666667]\n",
      " [0.68055556 0.38888889 0.38888889 0.375      0.375      0.375\n",
      "  0.375      0.38888889]\n",
      " [0.65277778 0.38888889 0.40277778 0.34722222 0.34722222 0.34722222\n",
      "  0.34722222 0.27777778]\n",
      " [0.63888889 0.40277778 0.375      0.36111111 0.36111111 0.36111111\n",
      "  0.36111111 0.36111111]\n",
      " [0.65277778 0.375      0.34722222 0.30555556 0.30555556 0.30555556\n",
      "  0.31944444 0.30555556]\n",
      " [0.59722222 0.36111111 0.34722222 0.31944444 0.30555556 0.30555556\n",
      "  0.30555556 0.34722222]\n",
      " [0.625      0.34722222 0.36111111 0.33333333 0.33333333 0.33333333\n",
      "  0.34722222 0.36111111]\n",
      " [0.59722222 0.36111111 0.34722222 0.31944444 0.30555556 0.30555556\n",
      "  0.30555556 0.38888889]\n",
      " [0.56944444 0.33333333 0.33333333 0.29166667 0.30555556 0.30555556\n",
      "  0.30555556 0.29166667]\n",
      " [0.56944444 0.36111111 0.31944444 0.30555556 0.31944444 0.31944444\n",
      "  0.31944444 0.30555556]\n",
      " [0.55555556 0.34722222 0.30555556 0.29166667 0.29166667 0.29166667\n",
      "  0.29166667 0.33333333]\n",
      " [0.58333333 0.34722222 0.30555556 0.31944444 0.30555556 0.30555556\n",
      "  0.30555556 0.33333333]\n",
      " [0.55555556 0.34722222 0.29166667 0.30555556 0.30555556 0.30555556\n",
      "  0.30555556 0.34722222]\n",
      " [0.58333333 0.33333333 0.31944444 0.30555556 0.29166667 0.29166667\n",
      "  0.29166667 0.34722222]\n",
      " [0.56944444 0.34722222 0.27777778 0.30555556 0.30555556 0.30555556\n",
      "  0.30555556 0.34722222]\n",
      " [0.58333333 0.33333333 0.31944444 0.30555556 0.30555556 0.30555556\n",
      "  0.30555556 0.34722222]\n",
      " [0.52777778 0.31944444 0.29166667 0.30555556 0.30555556 0.30555556\n",
      "  0.30555556 0.34722222]\n",
      " [0.54166667 0.33333333 0.31944444 0.30555556 0.31944444 0.31944444\n",
      "  0.31944444 0.33333333]\n",
      " [0.52777778 0.33333333 0.29166667 0.30555556 0.30555556 0.30555556\n",
      "  0.30555556 0.31944444]\n",
      " [0.54166667 0.34722222 0.27777778 0.30555556 0.30555556 0.30555556\n",
      "  0.30555556 0.33333333]\n",
      " [0.54166667 0.34722222 0.29166667 0.29166667 0.29166667 0.29166667\n",
      "  0.29166667 0.31944444]\n",
      " [0.54166667 0.34722222 0.27777778 0.29166667 0.29166667 0.29166667\n",
      "  0.29166667 0.31944444]\n",
      " [0.56944444 0.34722222 0.27777778 0.27777778 0.27777778 0.27777778\n",
      "  0.27777778 0.31944444]\n",
      " [0.52777778 0.33333333 0.27777778 0.27777778 0.27777778 0.27777778\n",
      "  0.27777778 0.33333333]\n",
      " [0.52777778 0.34722222 0.26388889 0.27777778 0.27777778 0.27777778\n",
      "  0.27777778 0.31944444]\n",
      " [0.52777778 0.33333333 0.29166667 0.25       0.26388889 0.26388889\n",
      "  0.26388889 0.33333333]]\n",
      "Lowest error achieved: 0.2500\n",
      "\t k= 25 - l= inf - weighting= False]\n",
      "\t k= 30 - l= 3 - weighting= True]\n",
      "\t k= 30 - l= inf - weighting= False]\n",
      "----------\n",
      "Unweighted\n",
      "[[0.61111111 0.375      0.41666667 0.38888889 0.41666667 0.41666667\n",
      "  0.41666667 0.41666667]\n",
      " [0.63888889 0.38888889 0.41666667 0.40277778 0.38888889 0.40277778\n",
      "  0.38888889 0.44444444]\n",
      " [0.58333333 0.40277778 0.45833333 0.44444444 0.44444444 0.45833333\n",
      "  0.44444444 0.51388889]\n",
      " [0.625      0.375      0.38888889 0.40277778 0.38888889 0.38888889\n",
      "  0.38888889 0.375     ]\n",
      " [0.51388889 0.34722222 0.44444444 0.38888889 0.40277778 0.40277778\n",
      "  0.40277778 0.43055556]\n",
      " [0.65277778 0.33333333 0.38888889 0.375      0.36111111 0.36111111\n",
      "  0.36111111 0.23611111]\n",
      " [0.51388889 0.44444444 0.43055556 0.40277778 0.41666667 0.38888889\n",
      "  0.41666667 0.29166667]\n",
      " [0.59722222 0.36111111 0.375      0.40277778 0.41666667 0.43055556\n",
      "  0.43055556 0.31944444]\n",
      " [0.47222222 0.51388889 0.40277778 0.40277778 0.375      0.375\n",
      "  0.40277778 0.375     ]\n",
      " [0.5        0.45833333 0.36111111 0.38888889 0.375      0.375\n",
      "  0.38888889 0.36111111]\n",
      " [0.44444444 0.38888889 0.41666667 0.45833333 0.45833333 0.45833333\n",
      "  0.45833333 0.40277778]\n",
      " [0.54166667 0.34722222 0.375      0.33333333 0.33333333 0.33333333\n",
      "  0.33333333 0.29166667]\n",
      " [0.54166667 0.33333333 0.34722222 0.29166667 0.29166667 0.29166667\n",
      "  0.29166667 0.36111111]\n",
      " [0.65277778 0.375      0.34722222 0.30555556 0.31944444 0.31944444\n",
      "  0.31944444 0.41666667]\n",
      " [0.5        0.45833333 0.41666667 0.41666667 0.41666667 0.41666667\n",
      "  0.41666667 0.36111111]\n",
      " [0.69444444 0.31944444 0.29166667 0.33333333 0.31944444 0.31944444\n",
      "  0.31944444 0.40277778]\n",
      " [0.69444444 0.33333333 0.30555556 0.31944444 0.31944444 0.31944444\n",
      "  0.31944444 0.34722222]\n",
      " [0.48611111 0.52777778 0.44444444 0.38888889 0.40277778 0.40277778\n",
      "  0.40277778 0.41666667]\n",
      " [0.65277778 0.29166667 0.31944444 0.29166667 0.29166667 0.29166667\n",
      "  0.29166667 0.33333333]\n",
      " [0.54166667 0.52777778 0.40277778 0.44444444 0.45833333 0.45833333\n",
      "  0.45833333 0.51388889]\n",
      " [0.5        0.43055556 0.375      0.33333333 0.34722222 0.36111111\n",
      "  0.34722222 0.41666667]\n",
      " [0.55555556 0.43055556 0.5        0.47222222 0.45833333 0.43055556\n",
      "  0.40277778 0.56944444]\n",
      " [0.45833333 0.33333333 0.41666667 0.36111111 0.33333333 0.375\n",
      "  0.33333333 0.43055556]\n",
      " [0.51388889 0.45833333 0.5        0.51388889 0.48611111 0.43055556\n",
      "  0.44444444 0.40277778]\n",
      " [0.36111111 0.34722222 0.30555556 0.34722222 0.31944444 0.375\n",
      "  0.33333333 0.25      ]\n",
      " [0.34722222 0.36111111 0.40277778 0.36111111 0.36111111 0.31944444\n",
      "  0.36111111 0.45833333]\n",
      " [0.45833333 0.31944444 0.40277778 0.36111111 0.34722222 0.38888889\n",
      "  0.38888889 0.33333333]\n",
      " [0.63888889 0.38888889 0.30555556 0.27777778 0.29166667 0.29166667\n",
      "  0.30555556 0.30555556]\n",
      " [0.51388889 0.44444444 0.52777778 0.51388889 0.51388889 0.47222222\n",
      "  0.5        0.44444444]\n",
      " [0.40277778 0.44444444 0.38888889 0.40277778 0.41666667 0.45833333\n",
      "  0.43055556 0.25      ]]\n",
      "Lowest error achieved: 0.2361\n",
      "\t k= 6 - l= inf - weighting= False]\n"
     ]
    }
   ],
   "source": [
    "print('SUMMARY')\n",
    "print('-'*20)\n",
    "print('Row -> k (1 to 30)')\n",
    "print('Col -> l (-1, 1, 2, 3, 4, 5, 6, inf)')\n",
    "print('-'*10)\n",
    "print('Weighted')\n",
    "print(inaccuracies[:,:,0])\n",
    "best_accuracy = np.min(inaccuracies[:,:,0])\n",
    "best_k, best_metric, best_weighting = np.where(inaccuracies == best_accuracy)\n",
    "print(f\"Lowest error achieved: {best_accuracy:0.4f}\")\n",
    "for k, l, w in zip(best_k, best_metric, best_weighting):\n",
    "    print(f\"\\t k= {k+1} - l= {l_norms[l]} - weighting= {weighting_options[w]}]\")\n",
    "print('-'*10)\n",
    "print('Unweighted')\n",
    "print(inaccuracies[:,:,1])\n",
    "best_accuracy = np.min(inaccuracies[:,:,1])\n",
    "best_k, best_metric, best_weighting = np.where(inaccuracies == best_accuracy)\n",
    "print(f\"Lowest error achieved: {best_accuracy:0.4f}\")\n",
    "for k, l, w in zip(best_k, best_metric, best_weighting):\n",
    "    print(f\"\\t k= {k+1} - l= {l_norms[l]} - weighting= {weighting_options[w]}]\")\n",
    "# print(inaccuracies[inaccuracies[:,:,0] != inaccuracies[:,:,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
